{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Author Prediction\n",
    "- checking gpu stats and limiting gpu memory\n",
    "- importing dataset from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.4\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "# import ipyparallel as ipp\n",
    "# c = ipp.Client(profile=\"slurm\")\n",
    "# c.ids\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda gpu is available: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3419848, 127)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "# import pickle5 as pickle\n",
    "\n",
    "is_cuda_gpu_available = tf.test.is_gpu_available(cuda_only=True)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.set_logical_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.LogicalDeviceConfiguration(memory_limit=2024)])\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "print(\"cuda gpu is available: {}\".format(is_cuda_gpu_available))\n",
    "\n",
    "#file_name = \"data/vision_forward_graph_data_local_05_08_22.pkl\"\n",
    "file_name = \"data/vision_forward_graph_data_08_09_22.pkl\"\n",
    "with open(file_name, 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# importing utility functions\n",
    "%run author_vision_util.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/jobs/12816994/ipykernel_26085/2857450278.py:9: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  chosen_conversation_ids = sample(df_conversations, n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen 507 conversations and gotten 517790 from twitter compared to 514793 from reddit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(514793, 127)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = equalize_samples(df)\n",
    "df = df[df[\"platform\"] == \"reddit\"]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Create a one hot vector representation of the possible authors\n",
    "- create an artificial user that represents a new user in a conversation up to that point\n",
    "- get a matrix with the authors as columns and a 1 if the author wrote the post\n",
    "- join it with the feature matrix\n",
    "- drop the author column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Author_is_new\n",
       "False            260759\n",
       "True             254034\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute a fake user that symbolizes that the given user has not been seen at a given stage in the conversation\n",
    "df_conversation_authors = df[[\"conversation_id\", \"author\", \"current_time\"]]\n",
    "first_times = df_conversation_authors.groupby([\"conversation_id\", \"author\"]).min()\n",
    "\n",
    "def is_new_author(row):\n",
    "    earliest_author_post = first_times.loc[row[\"conversation_id\"],row[\"author\"]]\n",
    "    current_post_time = row[\"current_time\"]\n",
    "    return  earliest_author_post >= current_post_time\n",
    "\n",
    "new_author_column = df[[\"conversation_id\", \"author\", \"current_time\"]].apply(is_new_author, axis=1)\n",
    "new_author_column= new_author_column.rename(columns={'current_time':\"Author_is_new\"})\n",
    "#new_author_column.describe()\n",
    "# current author has not been the beam_node\n",
    "new_author_column.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_new_author_column(df):\n",
    "    author_one_hot = pd.get_dummies(df.author, prefix=\"Author\", sparse=True)\n",
    "    # make author cells 0 that are now represented as \"new author\"\n",
    "    author_one_hot = author_one_hot.astype(bool).apply(lambda x: x & ~new_author_column.Author_is_new).astype(int)\n",
    "    # delete columns that are all 0 \n",
    "    author_one_hot = author_one_hot.loc[:, (author_one_hot != 0).any(axis=0)]\n",
    "    # join the new author column to the labels\n",
    "    labels = author_one_hot.join(new_author_column.astype(int))\n",
    "    features = take_features(df, [\"author\", \"current_time\", \"beam_node_time\"])\n",
    "    combined_set = features.join(labels)\n",
    "    return combined_set, features, labels\n",
    "\n",
    "combined_set, features, labels = compute_new_author_column(df)\n",
    "# combined_set.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_set = combined_set.sparse.to_coo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Training NN to predict the author that would write next\n",
    "- included a \"new author\" category to capture predicting unknown authors\n",
    "- using multi-class classification (instead of multi-label)\n",
    "- relu/sigmoid activation functions have same effect\n",
    "- precision grew significantly when adding more than 3-5 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split training and test set\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "from keras.optimizer_v2.rmsprop import RMSprop  # selecting train and test datasets\n",
    "train, test = train_test_split(combined_set, test_size=0.2, shuffle=False)\n",
    "print(\"split training and test set\")\n",
    "\n",
    "# Shuffle your dataset \n",
    "# shuffle_df = combined_set.sample(frac=1)\n",
    "\n",
    "# Define a size for your train set \n",
    "# train_size = int(0.7 * len(combined_set))\n",
    "\n",
    "# Split your dataset \n",
    "# train = shuffle_df[:train_size]\n",
    "# test = shuffle_df[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seperated features and y with shapes:\n",
      "(411834, 117)\n",
      "(411834, 3653)\n",
      "inputshape is (117,)\n",
      "defined model as [<keras.layers.core.dense.Dense object at 0x2aab608a2b30>, <keras.layers.core.dense.Dense object at 0x2aab52460b80>, <keras.layers.core.dense.Dense object at 0x2aab524cbb20>, <keras.layers.core.dense.Dense object at 0x2aaaae81faf0>, <keras.layers.core.dense.Dense object at 0x2aaaae81e2f0>, <keras.layers.core.dense.Dense object at 0x2aaaae81da80>, <keras.layers.core.dense.Dense object at 0x2aab69a0aef0>]\n",
      "compiled model\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "y = train.drop(features.columns, axis=1)\n",
    "x = train.drop(labels.columns, axis=1)\n",
    "print(\"seperated features and y with shapes:\")\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# import tensorflow and train the model\n",
    "# print(tf.__version__)\n",
    "input_shape = (x.shape[1],)\n",
    "output_shape = y.shape[1]\n",
    "print(\"inputshape is {}\".format(input_shape))\n",
    "model = Sequential([\n",
    "    Dense(output_shape, activation='relu', input_shape=input_shape),\n",
    "    Dense(output_shape, activation='relu', input_shape=input_shape),\n",
    "    Dense(output_shape, activation='relu', input_shape=input_shape),        \n",
    "    Dense(output_shape, activation='relu', input_shape=input_shape),\n",
    "    Dense(output_shape, activation='relu', input_shape=input_shape),\n",
    "    Dense(output_shape, activation='relu', input_shape=input_shape),    \n",
    "    Dense(output_shape, activation='softmax', input_shape=input_shape)\n",
    "])\n",
    "print(\"defined model as {}\".format(model.layers))\n",
    "# stochastic gradient descend as a classifier seem appropriate\n",
    "model.compile(\n",
    "    optimizer=RMSprop(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['categorical_accuracy', 'accuracy' ,'mae']\n",
    ")\n",
    "print(\"compiled model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12870/12870 [==============================] - 3471s 270ms/step - loss: 795.8341 - categorical_accuracy: 0.4944 - accuracy: 0.4944 - mae: 4.1186e-04\n",
      "3218/3218 [==============================] - 137s 42ms/step - loss: 6.8932 - categorical_accuracy: 0.4645 - accuracy: 0.4645 - mae: 4.0265e-04\n",
      "the accuracy on the training set is cat acc 0.4644761383533478, reg acc 0.4644761383533478 and the mae is 0.0004026502138003707\n"
     ]
    }
   ],
   "source": [
    "#model.fit(x, y, epochs=3)\n",
    "model.fit(x, y)\n",
    "#model.fit(x, y, epochs=10, shuffle=True)\n",
    "# evaluate the model on the test set\n",
    "test_y = test.drop(features.columns, axis=1)\n",
    "test_x = test.drop(labels.columns, axis=1)\n",
    "#test_x = test_x.drop(\"timedelta\", axis=1)\n",
    "\n",
    "loss, cat_accuracy, accuracy, mae = model.evaluate(test_x, test_y)\n",
    "print(\"the accuracy on the training set is cat acc {}, reg acc {} and the mae is {}\".format(cat_accuracy, accuracy, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.5673113 ],\n",
       "        [0.60965544],\n",
       "        [0.5660656 ],\n",
       "        [0.60802406],\n",
       "        [0.5701584 ]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#print(labels.columns)\n",
    "# some pandas alchemy to sample  2 rows of each conversation\n",
    "sample_df = df.sample(frac=1).reset_index(drop=True).groupby('conversation_id').apply(lambda x: x.sample(n=1)).reset_index(drop = True)\n",
    "sample_features = take_features(sample_df, [\"author\", \"current_time\", \"beam_node_time\"])\n",
    "sample_prediction = model.predict(sample_features)\n",
    "np.matrix(sample_prediction)[0:5, -1] # the last row is the \"new author column\" label and should contain a high value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Predicting the author presence based on prediction probabilities\n",
    "- compute predictions for the whole dataframe\n",
    "- drop features and non-features except conversation and platform\n",
    "- wide to long the authors to make them a index\n",
    "- groupby conversation and platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(514793, 3653)\n"
     ]
    }
   ],
   "source": [
    "all_features = take_features(df, [\"author\", \"current_time\", \"beam_node_time\"])\n",
    "predictions = model.predict(all_features)\n",
    "column_names = labels.columns\n",
    "predictions = pd.DataFrame(predictions, columns=column_names)\n",
    "print(type(predictions))\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(514793, 2)\n"
     ]
    }
   ],
   "source": [
    "all_non_features = df[[\"conversation_id\", \"platform\"]]\n",
    "print(type(all_non_features))\n",
    "print(all_non_features.shape)\n",
    "all_non_features.reset_index(drop=True, inplace=True)\n",
    "joined_dataframe = all_non_features.join(predictions)\n",
    "# not_needed_list = [\"beam_node\", \"has_followed_path\", \"has_follow_path\", \"beam_node_author\", \"current\"]\n",
    "# author_predictions = joined_dataframe.drop(not_needed_list, axis=1)\n",
    "# joined_dataframe.groupby([\"platform\", \"conversation_id\"]).mean()\n",
    "# joined_dataframe[\"id\"] = joined_dataframe.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5.147930e+05\n",
       "mean     5.560513e-01\n",
       "std      5.971310e-02\n",
       "min      5.119365e-16\n",
       "25%      5.469702e-01\n",
       "50%      5.757409e-01\n",
       "75%      5.847765e-01\n",
       "max      9.999920e-01\n",
       "Name: Author_is_new, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_dataframe.Author_is_new.describe() # no idea why that is the same prediction of all the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Author_2700</th>\n",
       "      <th>Author_80313</th>\n",
       "      <th>Author_100895</th>\n",
       "      <th>Author_139565</th>\n",
       "      <th>Author_142486</th>\n",
       "      <th>Author_186373</th>\n",
       "      <th>Author_208252</th>\n",
       "      <th>Author_231696</th>\n",
       "      <th>Author_237258</th>\n",
       "      <th>Author_270213</th>\n",
       "      <th>...</th>\n",
       "      <th>Author_99775268</th>\n",
       "      <th>Author_99828634</th>\n",
       "      <th>Author_99859100</th>\n",
       "      <th>Author_99883498</th>\n",
       "      <th>Author_99922107</th>\n",
       "      <th>Author_99966650</th>\n",
       "      <th>Author_99974100</th>\n",
       "      <th>Author_99979114</th>\n",
       "      <th>Author_99983170</th>\n",
       "      <th>Author_is_new</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platform</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>reddit</th>\n",
       "      <th>174503</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.590909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 3653 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Author_2700  Author_80313  Author_100895  \\\n",
       "platform conversation_id                                             \n",
       "reddit   174503              0.000001      0.000035       0.000004   \n",
       "\n",
       "                          Author_139565  Author_142486  Author_186373  \\\n",
       "platform conversation_id                                                \n",
       "reddit   174503                0.000436       0.000008       0.000004   \n",
       "\n",
       "                          Author_208252  Author_231696  Author_237258  \\\n",
       "platform conversation_id                                                \n",
       "reddit   174503                0.000001       0.000001        0.00001   \n",
       "\n",
       "                          Author_270213  ...  Author_99775268  \\\n",
       "platform conversation_id                 ...                    \n",
       "reddit   174503                0.000006  ...         0.000023   \n",
       "\n",
       "                          Author_99828634  Author_99859100  Author_99883498  \\\n",
       "platform conversation_id                                                      \n",
       "reddit   174503                  0.000002         0.000001         0.000007   \n",
       "\n",
       "                          Author_99922107  Author_99966650  Author_99974100  \\\n",
       "platform conversation_id                                                      \n",
       "reddit   174503                  0.000063         0.000001         0.000004   \n",
       "\n",
       "                          Author_99979114  Author_99983170  Author_is_new  \n",
       "platform conversation_id                                                   \n",
       "reddit   174503                  0.000002          0.00001       0.590909  \n",
       "\n",
       "[1 rows x 3653 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joined_dataframe.describe()\n",
    "joined_dataframe = joined_dataframe.groupby([\"platform\", \"conversation_id\"]).mean()\n",
    "joined_dataframe.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Author_</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platform</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">reddit</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">174503</th>\n",
       "      <th>2700</th>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80313</th>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100895</th>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Author_\n",
       "platform conversation_id author_id          \n",
       "reddit   174503          2700       0.000001\n",
       "                         80313      0.000035\n",
       "                         100895     0.000004"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "author_predictions_existing = joined_dataframe.drop([\"Author_is_new\"], axis=1)\n",
    "author_predictions_existing.reset_index(level=['platform', 'conversation_id'],inplace=True)\n",
    "author_predictions_existing_reshaped = pd.wide_to_long(author_predictions_existing, stubnames=\"Author_\", i=['platform', 'conversation_id'], j=\"author_id\")\n",
    "author_predictions_existing_reshaped.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# avg_author_pred = author_predictions_existing_reshaped.groupby([\"platform\", \"conversation_id\", \"author_id\"]).mean()\n",
    "# avg_author_pred.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Author_</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platform</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">reddit</th>\n",
       "      <th>174503</th>\n",
       "      <td>0.000112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203904</th>\n",
       "      <td>0.000115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209098</th>\n",
       "      <td>0.000119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Author_\n",
       "platform conversation_id          \n",
       "reddit   174503           0.000112\n",
       "         203904           0.000115\n",
       "         209098           0.000119"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_conversation_pred  = author_predictions_existing_reshaped.groupby([\"platform\", \"conversation_id\"]).mean()\n",
    "avg_conversation_pred.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Author_\n",
      "platform         \n",
      "reddit    0.00012\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author_</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platform</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>reddit</th>\n",
       "      <td>0.00012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Author_\n",
       "platform         \n",
       "reddit    0.00012"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_platform_pred = avg_conversation_pred.groupby([\"platform\"]).mean()\n",
    "print(avg_platform_pred)\n",
    "avg_platform_pred # picking the correct author seems to be exceedingly difficult#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Notes\n",
    "- inserting the new author column increased precision times 10\n",
    "- categorical accuracy and regular accuracy match (which is weird)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (authorvision)",
   "language": "python",
   "name": "author_vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
