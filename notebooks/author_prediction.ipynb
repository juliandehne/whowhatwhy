{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Author Prediction\n",
    "\n",
    "It is possible to predict an author or \"new author\" at same time by defining categories as 1 if a author is to be predicted but\n",
    "only if it is not a new author. Because of memory, only twitter or reddit data can be predicted in one run.\n",
    "The full dataset does not fit in laptops memory and is computed on the cluster (which in turn has no gpu support)\n",
    "\n",
    "The probability of predicting an author is calculated for each relationship (root distance to another node, reply distance to other nodes, and reply distance to nodes with the same author. In future also the author follower network will be included in the feature set.\n",
    "\n",
    "The overall sum of the probability of predicting an author (in average) will be interpreted as the likelihood of any author writing in any time in the conversation (again, because it is not a new author). This will then seen as the author being present in the conversation because it is another measure of a author being available in all branches and positions in the conversation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.10\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "# import ipyparallel as ipp\n",
    "# c = ipp.Client(profile=\"slurm\")\n",
    "# c.ids\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "cuda gpu is available: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 14:49:35.364911: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-16 14:49:35.365252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-16 14:49:35.365472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-16 14:49:35.365778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-16 14:49:35.366006: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-16 14:49:35.366191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 2600 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": "(809823, 81)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "# import pickle5 as pickle\n",
    "\n",
    "is_cuda_gpu_available = tf.test.is_gpu_available(cuda_only=True)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.set_logical_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.LogicalDeviceConfiguration(memory_limit=2024)])\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "print(\"cuda gpu is available: {}\".format(is_cuda_gpu_available))\n",
    "\n",
    "file_name = \"data/vision_forward_graph_data_local_05_08_22.pkl\"\n",
    "# file_name = \"data/vision_forward_graph_data_08_09_22.pkl\"\n",
    "with open(file_name, 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# importing utility functions\n",
    "%run author_vision_util.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen 24 conversations and gotten 28579 from twitter compared to 24497 from reddit\n"
     ]
    },
    {
     "data": {
      "text/plain": "(24497, 81)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = equalize_samples(df)\n",
    "df = df[df[\"platform\"] == \"reddit\"]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Create a one hot vector representation of the possible authors\n",
    "- create an artificial user that represents a new user in a conversation up to that point\n",
    "- get a matrix with the authors as columns and a 1 if the author wrote the post\n",
    "- join it with the feature matrix\n",
    "- drop the author column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Author_is_new\nFalse            14982\nTrue              9515\ndtype: int64"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute a fake user that symbolizes that the given user has not been seen at a given stage in the conversation\n",
    "df_conversation_authors = df[[\"conversation_id\", \"author\", \"current_time\"]]\n",
    "first_times = df_conversation_authors.groupby([\"conversation_id\", \"author\"]).min()\n",
    "\n",
    "def is_new_author(row):\n",
    "    earliest_author_post = first_times.loc[row[\"conversation_id\"],row[\"author\"]]\n",
    "    current_post_time = row[\"current_time\"]\n",
    "    return  earliest_author_post >= current_post_time\n",
    "\n",
    "new_author_column = df[[\"conversation_id\", \"author\", \"current_time\"]].apply(is_new_author, axis=1)\n",
    "new_author_column= new_author_column.rename(columns={'current_time':\"Author_is_new\"})\n",
    "#new_author_column.describe()\n",
    "# current author has not been the beam_node\n",
    "new_author_column.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_new_author_column(df):\n",
    "    author_one_hot = pd.get_dummies(df.author, prefix=\"Author\", sparse=True)\n",
    "    # make author cells 0 that are now represented as \"new author\"\n",
    "    author_one_hot = author_one_hot.astype(bool).apply(lambda x: x & ~new_author_column.Author_is_new).astype(int)\n",
    "    # delete columns that are all 0 \n",
    "    author_one_hot = author_one_hot.loc[:, (author_one_hot != 0).any(axis=0)]\n",
    "    # join the new author column to the labels\n",
    "    labels = author_one_hot.join(new_author_column.astype(int))\n",
    "    features = take_features(df, [\"author\", \"current_time\", \"beam_node_time\"])\n",
    "    combined_set = features.join(labels)\n",
    "    return combined_set, features, labels\n",
    "\n",
    "combined_set, features, labels = compute_new_author_column(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Training NN to predict the author that would write next\n",
    "- included a \"new author\" category to capture predicting unknown authors\n",
    "- using multi-class classification (instead of multi-label)\n",
    "- relu/sigmoid activation functions have same effect\n",
    "- precision grew significantly when adding more than 3-5 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split training and test set\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "from keras.optimizer_v2.rmsprop import RMSprop  # selecting train and test datasets\n",
    "train, test = train_test_split(combined_set, test_size=0.2, shuffle=False)\n",
    "print(\"split training and test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seperated features and y with shapes:\n",
      "(19597, 71)\n",
      "(19597, 136)\n",
      "inputshape is (71,)\n",
      "defined model as [<keras.layers.core.Dense object at 0x7f25b84cc820>, <keras.layers.core.Dense object at 0x7f25b864ab50>, <keras.layers.core.Dense object at 0x7f25b864a7f0>, <keras.layers.core.Dense object at 0x7f25b864a640>, <keras.layers.core.Dense object at 0x7f25b8655c40>, <keras.layers.core.Dense object at 0x7f25b8655ca0>, <keras.layers.core.Dense object at 0x7f25b8655820>]\n",
      "compiled model\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "y = train.drop(features.columns, axis=1)\n",
    "x = train.drop(labels.columns, axis=1)\n",
    "print(\"seperated features and y with shapes:\")\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# import tensorflow and train the model\n",
    "# print(tf.__version__)\n",
    "input_shape = (x.shape[1],)\n",
    "output_shape = y.shape[1]\n",
    "print(\"inputshape is {}\".format(input_shape))\n",
    "model = Sequential([\n",
    "    Dense(output_shape, activation='relu', input_shape=input_shape),\n",
    "    Dense(output_shape, activation='relu', input_shape=input_shape),\n",
    "    Dense(output_shape, activation='relu', input_shape=input_shape),        \n",
    "    Dense(output_shape, activation='relu', input_shape=input_shape),\n",
    "    Dense(output_shape, activation='relu', input_shape=input_shape),\n",
    "    Dense(output_shape, activation='relu', input_shape=input_shape),    \n",
    "    Dense(output_shape, activation='softmax', input_shape=input_shape)\n",
    "])\n",
    "print(\"defined model as {}\".format(model.layers))\n",
    "# stochastic gradient descend as a classifier seem appropriate\n",
    "model.compile(\n",
    "    optimizer=RMSprop(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['categorical_accuracy', 'accuracy' ,'mae']\n",
    ")\n",
    "print(\"compiled model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 2s 2ms/step - loss: 116.2682 - categorical_accuracy: 0.2636 - accuracy: 0.2636 - mae: 0.0127\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 8.6199 - categorical_accuracy: 0.2022 - accuracy: 0.2022 - mae: 0.0135\n",
      "the accuracy on the training set is cat acc 0.20224489271640778, reg acc 0.20224489271640778 and the mae is 0.013512490317225456\n"
     ]
    }
   ],
   "source": [
    "#model.fit(x, y, epochs=3)\n",
    "model.fit(x, y)\n",
    "#model.fit(x, y, epochs=10, shuffle=True)\n",
    "# evaluate the model on the test set\n",
    "test_y = test.drop(features.columns, axis=1)\n",
    "test_x = test.drop(labels.columns, axis=1)\n",
    "#test_x = test_x.drop(\"timedelta\", axis=1)\n",
    "\n",
    "loss, cat_accuracy, accuracy, mae = model.evaluate(test_x, test_y)\n",
    "print(\"the accuracy on the training set is cat acc {}, reg acc {} and the mae is {}\".format(cat_accuracy, accuracy, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "matrix([[0.39269435],\n        [0.39269435],\n        [0.39269435],\n        [0.39269435],\n        [0.39269435]], dtype=float32)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sample_df = df.sample(frac=1).reset_index(drop=True).groupby('conversation_id').apply(lambda x: x.sample(n=1)).reset_index(drop = True)\n",
    "sample_features = take_features(sample_df, [\"author\", \"current_time\", \"beam_node_time\"])\n",
    "sample_prediction = model.predict(sample_features)\n",
    "np.matrix(sample_prediction)[0:5, -1] # the last row is the \"new author column\" label and should contain a high value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Predicting the author presence based on prediction probabilities\n",
    "- compute predictions for the whole dataframe\n",
    "- drop features and non-features except conversation and platform\n",
    "- wide to long the authors to make them a index\n",
    "- groupby conversation and platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(24497, 136)\n"
     ]
    }
   ],
   "source": [
    "all_features = take_features(df, [\"author\", \"current_time\", \"beam_node_time\"])\n",
    "predictions = model.predict(all_features)\n",
    "column_names = labels.columns\n",
    "predictions = pd.DataFrame(predictions, columns=column_names)\n",
    "print(type(predictions))\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(24497, 2)\n"
     ]
    }
   ],
   "source": [
    "all_non_features = df[[\"conversation_id\", \"platform\"]]\n",
    "print(type(all_non_features))\n",
    "print(all_non_features.shape)\n",
    "all_non_features.reset_index(drop=True, inplace=True)\n",
    "joined_dataframe = all_non_features.join(predictions)\n",
    "# not_needed_list = [\"beam_node\", \"has_followed_path\", \"has_follow_path\", \"beam_node_author\", \"current\"]\n",
    "# author_predictions = joined_dataframe.drop(not_needed_list, axis=1)\n",
    "# joined_dataframe.groupby([\"platform\", \"conversation_id\"]).mean()\n",
    "# joined_dataframe[\"id\"] = joined_dataframe.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "count    24497.000000\nmean         0.392698\nstd          0.000399\nmin          0.389762\n25%          0.392694\n50%          0.392694\n75%          0.392694\nmax          0.436718\nName: Author_is_new, dtype: float64"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_dataframe.Author_is_new.describe() # no idea why that is the same prediction of all the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                          Author_538210  Author_1125209  Author_1920977  \\\nplatform conversation_id                                                  \nreddit   661614                0.007504        0.000886         0.00171   \n\n                          Author_1997405  Author_2280486  Author_2600925  \\\nplatform conversation_id                                                   \nreddit   661614                 0.000215        0.000142        0.025926   \n\n                          Author_3783312  Author_3919689  Author_4153484  \\\nplatform conversation_id                                                   \nreddit   661614                 0.000009        0.000184        0.000837   \n\n                          Author_4212372  ...  Author_92606372  \\\nplatform conversation_id                  ...                    \nreddit   661614                 0.000074  ...         0.000222   \n\n                          Author_93354514  Author_93631770  Author_94543394  \\\nplatform conversation_id                                                      \nreddit   661614                  0.005754         0.000022         0.000011   \n\n                          Author_95335292  Author_95977208  Author_97589063  \\\nplatform conversation_id                                                      \nreddit   661614                  0.006104         0.009734         0.001911   \n\n                          Author_98781300  Author_99195573  Author_is_new  \nplatform conversation_id                                                   \nreddit   661614                  0.004756            0.001       0.392694  \n\n[1 rows x 136 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Author_538210</th>\n      <th>Author_1125209</th>\n      <th>Author_1920977</th>\n      <th>Author_1997405</th>\n      <th>Author_2280486</th>\n      <th>Author_2600925</th>\n      <th>Author_3783312</th>\n      <th>Author_3919689</th>\n      <th>Author_4153484</th>\n      <th>Author_4212372</th>\n      <th>...</th>\n      <th>Author_92606372</th>\n      <th>Author_93354514</th>\n      <th>Author_93631770</th>\n      <th>Author_94543394</th>\n      <th>Author_95335292</th>\n      <th>Author_95977208</th>\n      <th>Author_97589063</th>\n      <th>Author_98781300</th>\n      <th>Author_99195573</th>\n      <th>Author_is_new</th>\n    </tr>\n    <tr>\n      <th>platform</th>\n      <th>conversation_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>reddit</th>\n      <th>661614</th>\n      <td>0.007504</td>\n      <td>0.000886</td>\n      <td>0.00171</td>\n      <td>0.000215</td>\n      <td>0.000142</td>\n      <td>0.025926</td>\n      <td>0.000009</td>\n      <td>0.000184</td>\n      <td>0.000837</td>\n      <td>0.000074</td>\n      <td>...</td>\n      <td>0.000222</td>\n      <td>0.005754</td>\n      <td>0.000022</td>\n      <td>0.000011</td>\n      <td>0.006104</td>\n      <td>0.009734</td>\n      <td>0.001911</td>\n      <td>0.004756</td>\n      <td>0.001</td>\n      <td>0.392694</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows Ã— 136 columns</p>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joined_dataframe.describe()\n",
    "joined_dataframe = joined_dataframe.groupby([\"platform\", \"conversation_id\"]).mean()\n",
    "joined_dataframe.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                     Author_\nplatform conversation_id author_id          \nreddit   661614          538210     0.007504\n                         1125209    0.000886\n                         1920977    0.001710",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>Author_</th>\n    </tr>\n    <tr>\n      <th>platform</th>\n      <th>conversation_id</th>\n      <th>author_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">reddit</th>\n      <th rowspan=\"3\" valign=\"top\">661614</th>\n      <th>538210</th>\n      <td>0.007504</td>\n    </tr>\n    <tr>\n      <th>1125209</th>\n      <td>0.000886</td>\n    </tr>\n    <tr>\n      <th>1920977</th>\n      <td>0.001710</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "author_predictions_existing = joined_dataframe.drop([\"Author_is_new\"], axis=1)\n",
    "author_predictions_existing.reset_index(level=['platform', 'conversation_id'],inplace=True)\n",
    "author_predictions_existing_reshaped = pd.wide_to_long(author_predictions_existing, stubnames=\"Author_\", i=['platform', 'conversation_id'], j=\"author_id\")\n",
    "author_predictions_existing_reshaped.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# avg_author_pred = author_predictions_existing_reshaped.groupby([\"platform\", \"conversation_id\", \"author_id\"]).mean()\n",
    "# avg_author_pred.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                           Author_\nplatform conversation_id          \nreddit   661614           0.004499\n         10955776         0.004499\n         15848916         0.004499",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Author_</th>\n    </tr>\n    <tr>\n      <th>platform</th>\n      <th>conversation_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">reddit</th>\n      <th>661614</th>\n      <td>0.004499</td>\n    </tr>\n    <tr>\n      <th>10955776</th>\n      <td>0.004499</td>\n    </tr>\n    <tr>\n      <th>15848916</th>\n      <td>0.004499</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_conversation_pred  = author_predictions_existing_reshaped.groupby([\"platform\", \"conversation_id\"]).mean()\n",
    "avg_conversation_pred.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Author_\n",
      "platform          \n",
      "reddit    0.004499\n"
     ]
    },
    {
     "data": {
      "text/plain": "           Author_\nplatform          \nreddit    0.004499",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Author_</th>\n    </tr>\n    <tr>\n      <th>platform</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>reddit</th>\n      <td>0.004499</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_platform_pred = avg_conversation_pred.groupby([\"platform\"]).mean()\n",
    "print(avg_platform_pred)\n",
    "avg_platform_pred # picking the correct author seems to be exceedingly difficult#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "                                     Author_\nplatform conversation_id author_id          \nreddit   661614          538210     0.007504\n                         1125209    0.000886\n                         1920977    0.001710",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>Author_</th>\n    </tr>\n    <tr>\n      <th>platform</th>\n      <th>conversation_id</th>\n      <th>author_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">reddit</th>\n      <th rowspan=\"3\" valign=\"top\">661614</th>\n      <th>538210</th>\n      <td>0.007504</td>\n    </tr>\n    <tr>\n      <th>1125209</th>\n      <td>0.000886</td>\n    </tr>\n    <tr>\n      <th>1920977</th>\n      <td>0.001710</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "author_predictions_existing = joined_dataframe.drop([\"Author_is_new\"], axis=1)\n",
    "author_predictions_existing.reset_index(level=['platform', 'conversation_id'],inplace=True)\n",
    "author_predictions_existing_reshaped = pd.wide_to_long(author_predictions_existing, stubnames=\"Author_\", i=['platform', 'conversation_id'], j=\"author_id\")\n",
    "author_predictions_existing_reshaped.head(3)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# avg_author_pred = author_predictions_existing_reshaped.groupby([\"platform\", \"conversation_id\", \"author_id\"]).mean()\n",
    "# avg_author_pred.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "                           Author_\nplatform conversation_id          \nreddit   661614           0.004499\n         10955776         0.004499\n         15848916         0.004499",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Author_</th>\n    </tr>\n    <tr>\n      <th>platform</th>\n      <th>conversation_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">reddit</th>\n      <th>661614</th>\n      <td>0.004499</td>\n    </tr>\n    <tr>\n      <th>10955776</th>\n      <td>0.004499</td>\n    </tr>\n    <tr>\n      <th>15848916</th>\n      <td>0.004499</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_conversation_pred  = author_predictions_existing_reshaped.groupby([\"platform\", \"conversation_id\"]).mean()\n",
    "avg_conversation_pred.head(3)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Author_\n",
      "platform          \n",
      "reddit    0.004499\n"
     ]
    },
    {
     "data": {
      "text/plain": "           Author_\nplatform          \nreddit    0.004499",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Author_</th>\n    </tr>\n    <tr>\n      <th>platform</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>reddit</th>\n      <td>0.004499</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_platform_pred = avg_conversation_pred.groupby([\"platform\"]).mean()\n",
    "print(avg_platform_pred)\n",
    "avg_platform_pred # picking the correct author seems to be exceedingly difficult#\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Notes\n",
    "- inserting the new author column increased precision times 10\n",
    "- categorical accuracy and regular accuracy match (which is weird)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                           Author_\nplatform conversation_id          \nreddit   661614           0.607306\n         10955776         0.607306\n         15848916         0.607306",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Author_</th>\n    </tr>\n    <tr>\n      <th>platform</th>\n      <th>conversation_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">reddit</th>\n      <th>661614</th>\n      <td>0.607306</td>\n    </tr>\n    <tr>\n      <th>10955776</th>\n      <td>0.607306</td>\n    </tr>\n    <tr>\n      <th>15848916</th>\n      <td>0.607306</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_conversation_pred  = author_predictions_existing_reshaped.groupby([\"platform\", \"conversation_id\"]).sum()\n",
    "avg_conversation_pred.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Author_\n",
      "platform          \n",
      "reddit    0.607303\n"
     ]
    },
    {
     "data": {
      "text/plain": "           Author_\nplatform          \nreddit    0.607303",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Author_</th>\n    </tr>\n    <tr>\n      <th>platform</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>reddit</th>\n      <td>0.607303</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_platform_pred = avg_conversation_pred.groupby([\"platform\"]).mean()\n",
    "print(avg_platform_pred)\n",
    "avg_platform_pred # picking the correct author seems to be exceedingly difficult#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Notes\n",
    "- inserting the new author column increased precision times 10\n",
    "- categorical accuracy and regular accuracy match (which is weird)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}